{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "# # Import from gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data and create the required structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "data = pd.read_csv('../../Datasets/yelp_labelled_processed/yelp_labelled_processed.csv')\n",
    "\n",
    "# Replace non-string reviews with strings (this is jsut a quirck of this dataset becasue some are np.nan)\n",
    "data['text'] = data['text'].apply(lambda review: str(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    new rule waitingtable almostalways cant wait i...\n",
       "1    giving twostar 'spretty rating might night new...\n",
       "2    staying planet hollywood acrossstreet saw good...\n",
       "3    foodgood price super expensive 8 buck extra la...\n",
       "4    worse company deal horrible work bring truck b...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 5 rows\n",
    "data['text'].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each string into an array\n",
    "sentences = data['text'].copy().apply(lambda string: string.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [new, rule, waitingtable, almostalways, cant, ...\n",
       "1    [giving, twostar, 'spretty, rating, might, nig...\n",
       "2    [staying, planet, hollywood, acrossstreet, saw...\n",
       "3    [foodgood, price, super, expensive, 8, buck, e...\n",
       "4    [worse, company, deal, horrible, work, bring, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 5 sentences\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The text data has to be an array of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the word2vec word embeddings (200 dimensions)\n",
    "word2vec_word_embeddings = Word2Vec(sentences = sentences,\n",
    "                           sg = 0, # 0 for continuous bag of words model, 1 for skip-gram model\n",
    "                           size = 100, # Dimensionality of the word vectors\n",
    "                           window = 5, # Maximum distance between the current and predicted word within a sentence\n",
    "                           workers = multiprocessing.cpu_count() - 2, # Use these many worker threads to train the model\n",
    "                           iter = 10) # Number of iterations (epochs) over the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13525"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of tokens that have been trained for\n",
    "len(word2vec_word_embeddings.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of each token\n",
    "word2vec_word_embeddings.wv.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at word simialrities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excellent', 0.7214541435241699),\n",
       " ('awesome', 0.7190586924552917),\n",
       " ('terrific', 0.6961654424667358),\n",
       " ('alsogreat', 0.6949751377105713),\n",
       " ('amazing', 0.681275486946106),\n",
       " ('greattoo', 0.6721410751342773),\n",
       " ('good', 0.6664098501205444),\n",
       " ('reallygreat', 0.6604778170585632),\n",
       " ('fantastic', 0.6590536236763),\n",
       " ('verygood', 0.6489591598510742)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the words that are most similar to 'great'\n",
    "word2vec_word_embeddings.wv.most_similar('great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.6349875926971436),\n",
       " ('notgood', 0.6148676872253418),\n",
       " ('reallybad', 0.6145668625831604),\n",
       " ('awful', 0.5781711339950562),\n",
       " (\"n'tgood\", 0.5546547174453735),\n",
       " ('horrible', 0.5532522797584534),\n",
       " ('poor', 0.522366464138031),\n",
       " ('horrid', 0.5187084078788757),\n",
       " ('sucked', 0.5163482427597046),\n",
       " (\"n'tgreat\", 0.48994702100753784)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the words that are most similar to 'great'\n",
    "word2vec_word_embeddings.wv.most_similar('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('burgerfry', 0.7724355459213257),\n",
       " ('onionring', 0.7235103845596313),\n",
       " ('hamburger', 0.7204596400260925),\n",
       " ('patty', 0.7153399586677551),\n",
       " ('cheeseburger', 0.704922616481781),\n",
       " ('poutine', 0.6989130973815918),\n",
       " ('veggieburger', 0.680663526058197),\n",
       " ('sweetpotatofry', 0.6724377870559692),\n",
       " ('burgergood', 0.6691707372665405),\n",
       " ('fry', 0.66410893201828)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the words that are most similar to 'great'\n",
    "word2vec_word_embeddings.wv.most_similar('burger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at the word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40580493 -0.56351244  0.23609917 -0.01513045  1.62838     1.0313561\n",
      " -0.44239405 -0.58281815  0.6831085  -0.7265927   0.0178313   1.1415402\n",
      " -1.494441   -1.1155494   1.412092   -0.6732566   0.90160966 -0.42537177\n",
      " -0.9525316  -0.69489723 -1.0825447   1.0854671  -0.15120716 -0.5315553\n",
      "  1.8485135  -0.61486644 -2.6897857  -0.06496173 -0.20794475  0.36508176\n",
      " -0.18880841 -0.19770506 -0.8825965   0.10867269 -1.3807807   0.81314355\n",
      "  3.2359798   0.04574855 -0.5769091  -0.1692346  -0.4798137   1.3301435\n",
      "  2.5049117  -0.6901831   0.17400044  0.7234964  -0.38093165 -1.7423817\n",
      "  1.2908051   1.0040889   0.77163196  2.3254035   0.06841435  1.2510766\n",
      "  1.0396721   0.01883189  0.80579334  2.0664282   0.97331715 -1.4259825\n",
      "  1.7379603   3.5708036   0.66354644  1.0676291  -0.25653598 -0.88472915\n",
      " -0.23615608 -0.13539356 -0.31772816  1.1915215  -0.27259427  0.31048393\n",
      "  1.1309578   0.6345404  -0.39328104 -2.6946926   0.39645115 -0.2220566\n",
      "  0.28574163 -0.7570241  -1.3633295   0.37991208 -1.6802174  -1.4869436\n",
      "  0.82327944  1.17568     0.43920973 -0.3772199   1.4339157   0.16088471\n",
      " -0.5213145  -0.55355036  0.66510123 -0.12258089 -1.2548727   2.1157894\n",
      "  0.37696707  0.8913441   0.08292926 -0.9254588 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxitron\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Have a look at the word embedding for 'great'\n",
    "print(word2vec_word_embeddings['great']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
