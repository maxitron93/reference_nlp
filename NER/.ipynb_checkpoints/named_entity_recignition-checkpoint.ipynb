{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import ne_chunk\n",
    "from nltk import pos_tag\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "data = pd.read_csv('../../Datasets/yelp_labelled_processed/yelp_labelled_processed.csv')[0:10]\n",
    "\n",
    "# Replace non-string reviews with strings (this is jsut a quirck of this dataset becasue some are np.nan)\n",
    "data['text'] = data['text'].apply(lambda review: str(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each string into an array\n",
    "data['tokens'] = data['text'].copy().apply(lambda string: string.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try nltk implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tagged'] = data['tokens'].apply(lambda tokens: pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply NER function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NER'] = data['tagged'].apply(lambda tagged: ne_chunk(tagged, binary=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Assigning the value of 'True' to the 'binary' parameter tells the algorithm to just recognize the named entities and not classify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree('S', [('new', 'JJ'), ('rule', 'NN'), ('waitingtable', 'JJ'), ('almostalways', 'NNS'), ('cant', 'VBP'), ('wait', 'NN'), ('inside', 'RB'), ('posted', 'VBD'), ('sign', 'JJ'), ('upfront', 'JJ'), ('cause', 'NN'), ('concern', 'NN'), ('seated', 'VBN'), ('patron', 'RB'), ('awful', 'JJ'), ('like', 'IN'), ('included', 'JJ'), ('apology', 'NN'), ('along', 'IN'), ('especially', 'RB'), ('cold', 'JJ'), ('p.s', 'JJ'), ('try', 'NN'), ('calling', 'VBG'), ('ahead', 'RB'), ('reserve', 'NN'), ('table', 'JJ'), ('thats', 'NNS'), ('waiting', 'VBG'), ('list', 'NN'), ('short', 'JJ'), ('otherwise', 'RB'), ('show', 'VBP'), ('reserve', 'NN'), ('placecould', 'NN'), ('wrong', 'JJ'), ('eye', 'NN'), ('rattle', 'VB'), ('away', 'RP'), ('hot', 'JJ'), ('beverage', 'NN'), ('must', 'MD'), ('mention', 'VB'), ('obsessed', 'VBD'), ('mad', 'NN')])\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first parse tree structure\n",
    "print(data['NER'].iloc[0].__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree('S', [('giving', 'VBG'), ('twostar', 'NN'), (\"'spretty\", 'CD'), ('rating', 'NN'), ('might', 'MD'), ('night', 'NN'), ('new', 'JJ'), ('east', 'JJ'), ('side', 'NN'), (\"n'tknow\", 'RB'), ('many', 'JJ'), ('hiddengem', 'NNS'), ('fiance', 'VBP'), ('met', 'VBN'), ('friend', 'NN'), ('drink', 'NN'), ('endedgetting', 'VBG'), ('thing', 'NN'), ('nibble', 'JJ'), ('first', 'JJ'), ('service', 'NN'), ('pretty', 'RB'), ('slow', 'JJ'), ('unusual', 'JJ'), ('restaurant', 'NN'), ('pretty', 'RB'), ('small', 'JJ'), ('galley', 'NN'), ('style', 'NN'), ('wouldthink', 'NN'), ('would', 'MD'), ('easy', 'VB'), ('server', 'RB'), ('routinely', 'RB'), ('hit', 'VBN'), ('table', 'JJ'), ('pas', 'NN'), ('fiance', 'NN'), ('ordered', 'VBD'), ('quinoa', 'JJ'), ('salad', 'NN'), ('said', 'VBD'), ('prettygood', 'NN'), ('dry', 'NNS'), (\"n'ttoo\", 'RB'), ('hungry', 'JJ'), ('simply', 'RB'), ('ordered', 'VBD'), ('came', 'VBD'), ('burnt', 'RB'), ('ordered', 'JJ'), ('side', 'NN'), ('fry', 'NN'), ('either', 'RB'), ('hard', 'JJ'), ('chewy', 'NN'), ('friendordered', 'VBD'), ('macaroni', 'JJ'), ('cheese', 'NN'), ('added', 'VBD'), ('chicken', 'JJ'), ('bacon', 'NN'), ('usual', 'JJ'), ('order', 'NN'), ('liked', 'VBD'), (\"can'tremember\", 'JJ'), ('lasttime', 'JJ'), ('thought', 'VBN'), ('huh', 'NN'), ('failed', 'VBD'), ('fry', 'NNS'), ('like', 'IN'), ('twostar', 'NN'), ('decor', 'NN'), ('good', 'JJ'), ('goodplace', 'NN'), ('conversation', 'NN'), ('might', 'MD'), ('backtry', 'VB'), ('expensive', 'JJ'), ('fare', 'NN'), ('ah', 'VBZ'), ('fry', 'JJ'), ('thing', 'NN'), ('dunno', 'NN'), ('man', 'NN')])\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the second parse tree structure\n",
    "print(data['NER'].iloc[1].__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the parse tree\n",
    "test = data['NER'].iloc[2]\n",
    "# test.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems like nltk's NER doesn't work so well.\n",
    "It's not describing anything as a named entity. Maybe because nothing is capitalized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try spacy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy's 'en_core_web_sm' model\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply POS tagging\n",
    "data['spacy_pos_tagged'] = data['text'].apply(lambda tokens: nlp(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply NER tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patron ORG\n",
      "p.s try ORG\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first text\n",
    "first_text = data['spacy_pos_tagged'][0]\n",
    "for token in first_text.ents:\n",
    "    print(token.text, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "night TIME\n",
      "first ORDINAL\n",
      "quinoa salad PERSON\n",
      "n'ttoo hungry PERSON\n",
      "can'tremember lasttime DATE\n",
      "twostar decor good goodplace ORG\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the second text\n",
    "first_text = data['spacy_pos_tagged'][1]\n",
    "for token in first_text.ents:\n",
    "    print(token.text, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hollywood GPE\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the third text\n",
    "first_text = data['spacy_pos_tagged'][2]\n",
    "for token in first_text.ents:\n",
    "    print(token.text, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 CARDINAL\n",
      "carneasada burrito FAC\n",
      "burrito n'tgetwrong ' PERSON\n",
      "3 CARDINAL\n",
      "n'tforget PERSON\n",
      "tomato PERSON\n",
      "one CARDINAL\n",
      "cucumber quarter DATE\n",
      "4 five CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the fourth text\n",
    "first_text = data['spacy_pos_tagged'][3]\n",
    "for token in first_text.ents:\n",
    "    print(token.text, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate mcdonalds ORG\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the sixth text\n",
    "first_text = data['spacy_pos_tagged'][5]\n",
    "for token in first_text.ents:\n",
    "    print(token.text, token.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This also doesn't seem to work so well.\n",
    "Apparently, the recognition and categorization of named entities strongly depends on the data that the recognizer has been trained on. This is something to keep in mind when implementing named entity recognition; it is often better to train and develop your own recognizer for specific use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the nltk NER on a tagged corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the corpus\n",
    "corpus = nltk.corpus.treebank.tagged_sents()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first sentence\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out the the first sentence\n",
    "tagged_sent_1 = ne_chunk(corpus[0], binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree('S', [Tree('PERSON', [('Pierre', 'NNP')]), Tree('ORGANIZATION', [('Vinken', 'NNP')]), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')])\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the parse tree structure\n",
    "print(tagged_sent_1.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the parse tree\n",
    "tagged_sent_1.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out the the second sentence\n",
    "tagged_sent_2 = ne_chunk(corpus[1], binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree('S', [Tree('PERSON', [('Mr.', 'NNP')]), Tree('PERSON', [('Vinken', 'NNP')]), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), Tree('ORGANIZATION', [('Elsevier', 'NNP')]), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), Tree('GPE', [('Dutch', 'NNP')]), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')])\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the parse tree structure\n",
    "print(tagged_sent_2.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the parse tree\n",
    "tagged_sent_2.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
